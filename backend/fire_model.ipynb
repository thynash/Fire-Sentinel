{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8667f5ab",
      "metadata": {
        "id": "8667f5ab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import segmentation_models_pytorch as smp\n",
        "import xarray as xr\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d274305b",
      "metadata": {
        "id": "d274305b"
      },
      "source": [
        "---------------- CONFIG ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "48f61f10",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "48f61f10"
      },
      "outputs": [],
      "source": [
        "ERA5_GRIB_PATH = \"../data/era5_input.grib\"       # Path to your ERA5 file\n",
        "FIRE_MASK_DIR = \"../data/viirs_masks\"                  # Folder of binary fire masks\n",
        "MODEL_SAVE_PATH = \"../models/unet_fire_model.pth\"\n",
        "VARIABLES = [\"t2m\", \"u10\", \"v10\", \"sp\", \"tp\"]        # Update if needed\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_SHAPE = (1800, 3598)  # Match this with mask dimensions\n",
        "MAX_SAMPLES = 100  # limit dataset size to speed up training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d5184c",
      "metadata": {
        "id": "a7d5184c"
      },
      "source": [
        "---------------- Dataset ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "57395c1a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "57395c1a"
      },
      "outputs": [],
      "source": [
        "class ERA5FireDataset(Dataset):\n",
        "    def __init__(self, grib_path, mask_dir, variables):\n",
        "        self.ds = xr.open_dataset(\n",
        "            grib_path,\n",
        "            engine=\"cfgrib\",\n",
        "            backend_kwargs={\"indexpath\": \"\", \"engine\": \"cfgrib\"}, # Explicitly specify backend engine\n",
        "            decode_timedelta=True\n",
        "        )\n",
        "\n",
        "        self.variables = variables\n",
        "        self.mask_dir = Path(mask_dir)\n",
        "        self.available_masks = sorted(self.mask_dir.glob(\"*.npy\"))\n",
        "\n",
        "        # Detect valid temporal dimension\n",
        "        self.temporal_dim = None\n",
        "        for var in self.variables:\n",
        "            if var in self.ds:\n",
        "                for dim in self.ds[var].dims:\n",
        "                    if dim.lower() in [\"time\", \"step\", \"valid_time\"]:\n",
        "                        self.temporal_dim = dim\n",
        "                        break\n",
        "            if self.temporal_dim:\n",
        "                break\n",
        "\n",
        "        if self.temporal_dim is None:\n",
        "            print(\"‚ö†Ô∏è  No temporal dimension detected. Assuming static GRIB file.\")\n",
        "            self.length = len(self.available_masks)\n",
        "        else:\n",
        "            time_len = self.ds.dims.get(self.temporal_dim, 1)\n",
        "            self.length = min(time_len, len(self.available_masks))\n",
        "\n",
        "        self.length = min(self.length, MAX_SAMPLES)\n",
        "        print(f\"üìä Temporal dim: {self.temporal_dim} | Training samples: {self.length}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        channels = []\n",
        "        for var in self.variables:\n",
        "            if var not in self.ds:\n",
        "                raise KeyError(f\"Variable '{var}' not found in GRIB file.\")\n",
        "            if self.temporal_dim:\n",
        "                arr = self.ds[var].isel({self.temporal_dim: idx}).values\n",
        "            else:\n",
        "                arr = self.ds[var].values\n",
        "            channels.append(arr)\n",
        "\n",
        "        x = np.stack(channels).astype(np.float32)\n",
        "        y = np.load(self.available_masks[idx]).astype(np.float32)\n",
        "        y = np.clip(y, 0, 1)\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        y = torch.from_numpy(y)\n",
        "\n",
        "        if x.shape[1:] != TARGET_SHAPE:\n",
        "            x = F.interpolate(x.unsqueeze(0), size=TARGET_SHAPE, mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "        if y.shape[1:] != TARGET_SHAPE:\n",
        "            y = F.interpolate(y.unsqueeze(0), size=TARGET_SHAPE, mode=\"nearest\").squeeze(0)\n",
        "\n",
        "        x = (x - x.mean()) / (x.std() + 1e-6)\n",
        "\n",
        "        if y.max() == 0:\n",
        "            y[0:10, 0:10] = 1.0\n",
        "\n",
        "        return x.float(), y.float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1162b0fd",
      "metadata": {
        "id": "1162b0fd"
      },
      "source": [
        "---------------- Training ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "58e613b6",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "58e613b6"
      },
      "outputs": [],
      "source": [
        "def train_unet():\n",
        "    print(\"üì¶ Loading dataset...\")\n",
        "    full_dataset = ERA5FireDataset(ERA5_GRIB_PATH, FIRE_MASK_DIR, VARIABLES)\n",
        "    dataloader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    print(\"üß† Building U-Net model...\")\n",
        "    model = smp.Unet(encoder_name=\"resnet18\", in_channels=len(VARIABLES), classes=1)  # Lighter encoder\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    dice = smp.losses.DiceLoss(mode=\"binary\", smooth=1e-5)\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def combined_loss(preds, targets):\n",
        "        if preds.shape != targets.shape:\n",
        "            targets = F.interpolate(targets, size=preds.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "        return dice(preds, targets) + bce(preds, targets)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"üöÄ Starting training...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "        for x, y in loop:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            if y.ndim == 3:\n",
        "                y = y.unsqueeze(1)\n",
        "            if x.ndim == 3:\n",
        "                x = x.unsqueeze(0)\n",
        "            try:\n",
        "                preds = model(x)\n",
        "                loss = combined_loss(preds, y)\n",
        "                if torch.isnan(loss):\n",
        "                    print(\"‚ùå NaN detected in loss, skipping batch.\")\n",
        "                    continue\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "            except RuntimeError as e:\n",
        "                if 'out of memory' in str(e):\n",
        "                    print(\"‚ùå CUDA OOM - skipping batch.\")\n",
        "                    torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"‚úÖ Epoch {epoch+1}: Avg Loss = {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    Path(\"models\").mkdir(exist_ok=True)\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(f\"üéØ Model saved to: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ab6651",
      "metadata": {
        "id": "81ab6651"
      },
      "source": [
        "---------------- Entry Point ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a7c71f13",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a7c71f13",
        "outputId": "9d98c1a0-4af7-4485-81ba-93769907fa32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loading dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-35-629722115.py\", line 2, in <cell line: 0>\n",
            "    train_unet()\n",
            "  File \"/tmp/ipython-input-32-3613901082.py\", line 3, in train_unet\n",
            "    full_dataset = ERA5FireDataset(ERA5_GRIB_PATH, FIRE_MASK_DIR, VARIABLES)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-31-1298596776.py\", line 3, in __init__\n",
            "    self.ds = xr.open_dataset(\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xarray/backends/api.py\", line 673, in open_dataset\n",
            "    backend = plugins.get_backend(engine)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xarray/backends/plugins.py\", line 202, in get_backend\n",
            "    raise ValueError(\n",
            "ValueError: unrecognized engine 'cfgrib' must be one of your download engines: ['h5netcdf', 'scipy', 'store']. To install additional dependencies, see:\n",
            "https://docs.xarray.dev/en/stable/user-guide/io.html \n",
            "https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 988, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-35-629722115.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-32-3613901082.py\u001b[0m in \u001b[0;36mtrain_unet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üì¶ Loading dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERA5FireDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERA5_GRIB_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIRE_MASK_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVARIABLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-31-1298596776.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grib_path, mask_dir, variables)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         self.ds = xr.open_dataset(\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mgrib_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/backends/plugins.py\u001b[0m in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mengines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0;34mf\"unrecognized engine '{engine}' must be one of your download engines: {list(engines)}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unrecognized engine 'cfgrib' must be one of your download engines: ['h5netcdf', 'scipy', 'store']. To install additional dependencies, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ValueError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_unet()"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}