{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import segmentation_models_pytorch as smp\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274305b",
   "metadata": {},
   "source": [
    "---------------- CONFIG ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f61f10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "ERA5_GRIB_PATH = \"../data/era5_input.grib\"       # Path to your ERA5 file\n",
    "FIRE_MASK_DIR = \"../data/viirs_masks\"                  # Folder of binary fire masks\n",
    "MODEL_SAVE_PATH = \"../models/unet_fire_model.pth\"\n",
    "VARIABLES = [\"t2m\", \"u10\", \"v10\", \"sp\", \"tp\"]        # Update if needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "TARGET_SHAPE = (1800, 3598)  # Match this with mask dimensions\n",
    "MAX_SAMPLES = 100  # limit dataset size to speed up training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5184c",
   "metadata": {},
   "source": [
    "---------------- Dataset ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57395c1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ERA5FireDataset(Dataset):\n",
    "    def __init__(self, grib_path, mask_dir, variables):\n",
    "        self.ds = xr.open_dataset(\n",
    "            grib_path,\n",
    "            engine=\"cfgrib\",\n",
    "            backend_kwargs={\"indexpath\": \"\"},\n",
    "            decode_timedelta=True\n",
    "        )\n",
    "\n",
    "        self.variables = variables\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.available_masks = sorted(self.mask_dir.glob(\"*.npy\"))\n",
    "\n",
    "        # Detect valid temporal dimension\n",
    "        self.temporal_dim = None\n",
    "        for var in self.variables:\n",
    "            if var in self.ds:\n",
    "                for dim in self.ds[var].dims:\n",
    "                    if dim.lower() in [\"time\", \"step\", \"valid_time\"]:\n",
    "                        self.temporal_dim = dim\n",
    "                        break\n",
    "            if self.temporal_dim:\n",
    "                break\n",
    "\n",
    "        if self.temporal_dim is None:\n",
    "            print(\"‚ö†Ô∏è  No temporal dimension detected. Assuming static GRIB file.\")\n",
    "            self.length = len(self.available_masks)\n",
    "        else:\n",
    "            time_len = self.ds.dims.get(self.temporal_dim, 1)\n",
    "            self.length = min(time_len, len(self.available_masks))\n",
    "\n",
    "        self.length = min(self.length, MAX_SAMPLES)\n",
    "        print(f\"üìä Temporal dim: {self.temporal_dim} | Training samples: {self.length}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        channels = []\n",
    "        for var in self.variables:\n",
    "            if var not in self.ds:\n",
    "                raise KeyError(f\"Variable '{var}' not found in GRIB file.\")\n",
    "            if self.temporal_dim:\n",
    "                arr = self.ds[var].isel({self.temporal_dim: idx}).values\n",
    "            else:\n",
    "                arr = self.ds[var].values\n",
    "            channels.append(arr)\n",
    "\n",
    "        x = np.stack(channels).astype(np.float32)\n",
    "        y = np.load(self.available_masks[idx]).astype(np.float32)\n",
    "        y = np.clip(y, 0, 1)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        y = torch.from_numpy(y)\n",
    "\n",
    "        if x.shape[1:] != TARGET_SHAPE:\n",
    "            x = F.interpolate(x.unsqueeze(0), size=TARGET_SHAPE, mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        if y.shape[1:] != TARGET_SHAPE:\n",
    "            y = F.interpolate(y.unsqueeze(0), size=TARGET_SHAPE, mode=\"nearest\").squeeze(0)\n",
    "\n",
    "        x = (x - x.mean()) / (x.std() + 1e-6)\n",
    "\n",
    "        if y.max() == 0:\n",
    "            y[0:10, 0:10] = 1.0\n",
    "\n",
    "        return x.float(), y.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162b0fd",
   "metadata": {},
   "source": [
    "---------------- Training ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e613b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_unet():\n",
    "    print(\"üì¶ Loading dataset...\")\n",
    "    full_dataset = ERA5FireDataset(ERA5_GRIB_PATH, FIRE_MASK_DIR, VARIABLES)\n",
    "    dataloader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(\"üß† Building U-Net model...\")\n",
    "    model = smp.Unet(encoder_name=\"resnet18\", in_channels=len(VARIABLES), classes=1)  # Lighter encoder\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    dice = smp.losses.DiceLoss(mode=\"binary\", smooth=1e-5)\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def combined_loss(preds, targets):\n",
    "        if preds.shape != targets.shape:\n",
    "            targets = F.interpolate(targets, size=preds.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        return dice(preds, targets) + bce(preds, targets)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"üöÄ Starting training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            if y.ndim == 3:\n",
    "                y = y.unsqueeze(1)\n",
    "            if x.ndim == 3:\n",
    "                x = x.unsqueeze(0)\n",
    "            try:\n",
    "                preds = model(x)\n",
    "                loss = combined_loss(preds, y)\n",
    "                if torch.isnan(loss):\n",
    "                    print(\"‚ùå NaN detected in loss, skipping batch.\")\n",
    "                    continue\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            except RuntimeError as e:\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(\"‚ùå CUDA OOM - skipping batch.\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"‚úÖ Epoch {epoch+1}: Avg Loss = {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    Path(\"models\").mkdir(exist_ok=True)\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"üéØ Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab6651",
   "metadata": {},
   "source": [
    "---------------- Entry Point ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c71f13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_unet()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
